---
title: "P8105 Homework 5"
output: github_document
date: "November 13, 2024"
---

```{r document setup, include = FALSE }
library(tidyverse)
set.seed(1)
```

## Problem 1
Estimate birthday probabilities 
```{r}
bday_sim <- function(n) {
  bdays <- sample(1:365, size = n, replace = TRUE)
  duplicate <- length(unique(bdays)) < n
  return(duplicate)
}

birthday_match_prob <- function(size_range, simulations_count) {
  probabilities <- sapply(size_range, function(size) {
    results <- replicate(simulations_count, bday_sim(size))
    mean(results)
  })
  
  results <- tibble(
    group_size = size_range,
    probability = probabilities
  )
  
  return(results)
}
```

Run the simulation and plot results
```{r}
group_sizes <- 2:50
simulations <- 10000

probability_data <- birthday_match_prob(group_sizes, simulations)

probability_data |> 
  ggplot(aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthdays",
    x = "Group Size",
    y = "Probability"
  ) +
  theme_minimal()
```

As group size increases the  probability of shared birthdays also increases. For around 23 people, the probability of at least two people sharing a birthday exceeds 50%.

## Problem 2
First set the design elements: 
Sample Size: n <- 30   
Standard Deviation: sigma <- 5    
True value of population mean: mu_values <- 0:6   
Number of simulations per mu value: iterations <- 5000  
Significance level for the t-test: alpha <- 0.05       

Define sim power
```{r}
sim_power <- function(samp_size = 30, true_mean = 0, true_sd = 5, alpha = 0.05) {
  sim_df <- tibble(
    x = rnorm(samp_size, true_mean, true_sd)
  )
    out_df <- sim_df %>%
    summarize(
      mu_hat = mean(x),  
      p_value = t.test(x, mu = 0) %>% broom::tidy() %>% pull(p.value)
    )
  return(out_df)
}

```

Run 5000 simulations
```{r}
sim_final <- expand_grid(
  true_mean = c(0, 1, 2, 3, 4, 5, 6),  
  iter = 1:5000                      
) %>%
  mutate(
    samp_res = map(true_mean, sim_power, samp_size = 30)  
  ) %>%
  unnest(samp_res)
```

Plotting the Average Estimate of Œº
```{r}
sim_final %>%
  group_by(true_mean) %>%
  summarize(avg_mu_hat = mean(mu_hat), .groups = 'drop') %>%
  ggplot(aes(x = true_mean, y = avg_mu_hat)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average Estimate of Œº hat vs. True Value of Œº",
    x = "True Value of Œº",
    y = "Average Estimate of Œº hat"
  ) +
  theme_minimal()
```

This graph demonstrates that as the true value of ùúáincreases, the average estimate closely follows the true value of ùúá.The diagonal line indicates that, on average, ùúá^ is an unbiased estimate of ùúá, regardless of the magnitude of 
ùúá. This reflects that the estimator for Œº performs well and is consistent as the true value of ùúáincreases.


Plot the average estimate of mu where the null hypothesis was rejected
```{r}
sim_final %>%
  filter(p_value < 0.05) %>%  
  group_by(true_mean) %>%
  summarize(avg_mu_hat_rejected = mean(mu_hat), .groups = 'drop') %>%
  ggplot(aes(x = true_mean, y = avg_mu_hat_rejected)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Average Estimate of Œº hat When the Null was Rejected",
    x = "True Value of Œº",
    y = "Average Estimate of Œº hat"
  ) +
  theme_minimal()
```

This plot shows that the average ùúá^ is only calculated for cases where the null hypothesis was rejected (where 
p <0.05). This plot shows a similar trend to the first, but as the true ùúáincreases, the power of the test increases, meaning that ùúá^ values where the null is rejected will be closer to the true value of ùúámore often. This suggests that when there is a true effect (Œº>0), the t-test is likely to reject the null hypothesis, and the observed estimates ùúá^ will be more representative of the true effect size.


## Problem 3
Load the homicide data
```{r, message=FALSE}
homicide_data <- read_csv("data/homicide-data.csv")
```

Combine city and state into a single variable, then summarize total and unsolved cases by location
```{r}
homicide_summary <- homicide_data |> 
  mutate(city_state = paste(city, state, sep = ", ")) |>
  group_by(city_state) |>
  summarize(
    total_cases = n(),
    unresolved_cases = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
```
The raw data consists of information on homicides across `r n_distinct(homicide_summary$city_state)` large U.S. cities, with `r nrow(homicide_data)` records. The dataset contains variables such as `reported_date`, `victim_last`, `victim_first`, `victim_race`, `victim_age`, `victim_sex`, `city`, `state`, `lat`, `lon`, and `disposition`. The reported_date ranges from 2007-01-01 to 2015-11-05, and victim ages from `r min(homicide_data$victim_age, na.rm = TRUE)` to 102, with some missing values. The disposition variable indicates the status of each case, with categories such as "Open/No arrest" representing unsolved homicides.


Calculate Proportion of Unsolved Cases for Baltimore
```{r}
baltimore_data <- homicide_summary |> filter(city_state == "Baltimore, MD")
baltimore_test <- prop.test(
  x = baltimore_data$unresolved_cases, 
  n = baltimore_data$total_cases
) |> broom::tidy()

baltimore_test |> select(estimate, conf.low, conf.high) |> knitr::kable()

```

Estimate Proportion of Unsolved Cases for All Cities
```{r, include=FALSE}
calculate_proportion <- function(unresolved, total) {
  prop.test(x = unresolved, n = total) |> broom::tidy()
}

city_proportions <- homicide_summary |>
  mutate(
    test_results = map2(unresolved_cases, total_cases, calculate_proportion)
  ) |> 
  unnest(cols = c(test_results)) |>
  select(city_state, estimate, conf.low, conf.high)

```
This table describes the estimated proportion and confidence intervals from the resulting tidy dataframe.

Visualizing the Results
```{r}
city_proportions |> 
  arrange(estimate) |> 
  mutate(city_state = factor(city_state, levels = city_state)) |>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Estimated Proportion of Unsolved Homicides by City",
    x = "City and State",
    y = "Proportion Unsolved (with 95% CI)"
  ) +
  theme_minimal()

```

In this plot cities are organized according to the proportion of unsolved homicides.


